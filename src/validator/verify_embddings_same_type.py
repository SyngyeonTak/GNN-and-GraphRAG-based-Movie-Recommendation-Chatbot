import faiss
import json
import numpy as np

# --- ì„¤ì • ---
# ê²€ì¦í•˜ê³  ì‹¶ì€ ë…¸ë“œ íƒ€ì…ê³¼ ê° íƒ€ì…ë³„ ì˜ˆì‹œ íƒ€ê²Ÿ
VERIFICATION_TARGETS = {
    "movie": "Toy Story",
    "actor": "Tom Hanks",
    "director": "Steven Spielberg",
    "genre": "Crime"
}
TOP_K = 10  # ëª‡ ê°œì˜ ìœ ì‚¬ í•­ëª©ì„ ë³¼ì§€ ì„¤ì •

def verify_single_embedding(node_type, target_name):
    """ì§€ì •ëœ ë…¸ë“œ íƒ€ì…ì˜ ì„ë² ë”© íŒŒì¼ê³¼ ë§¤í•‘ íŒŒì¼ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    
    faiss_index_path = f"./dataset/faiss/{node_type}_embeddings.faiss"
    mapping_path = f"./dataset/faiss/{node_type}_mapping.json"
    
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ Verifying Embeddings for Node Type: '{node_type.upper()}'")
    print(f"{'='*60}")

    # --- 1. FAISS ì¸ë±ìŠ¤ ë¡œë“œ ---
    print(f"--- Loading FAISS index from: {faiss_index_path} ---")
    try:
        index = faiss.read_index(faiss_index_path)
        print(f"Index loaded successfully.")
        print(f"Number of vectors in index: {index.ntotal}")
        print(f"Vector dimension: {index.d}")
    except Exception as e:
        print(f"ğŸ”´ Error loading FAISS index: {e}")
        return

    # --- 2. ë§¤í•‘ íŒŒì¼ ë¡œë“œ ---
    print(f"\n--- Loading mapping from: {mapping_path} ---")
    try:
        with open(mapping_path, 'r', encoding='utf-8') as f:
            idx_to_name = json.load(f)
            # JSONì€ í‚¤ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥í•˜ë¯€ë¡œ, ë‹¤ì‹œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
            idx_to_name = {int(k): v for k, v in idx_to_name.items()}
        print(f"Mapping loaded successfully. Total items: {len(idx_to_name)}")
    except Exception as e:
        print(f"ğŸ”´ Error loading mapping file: {e}")
        return

    # --- 3. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦ ---
    if index.ntotal != len(idx_to_name):
        print("\n[ğŸ”´ CRITICAL ERROR] The number of vectors in FAISS and items in the mapping do not match!")
    else:
        print("\n[âœ”ï¸ SANITY CHECK PASSED] Index and mapping counts match.")

    # --- 4. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ---
    print(f"\n--- Performing similarity search for: '{target_name}' ---")
    
    try:
        # ì´ë¦„ìœ¼ë¡œ ì¸ë±ìŠ¤ ì°¾ê¸°
        name_to_idx = {v: k for k, v in idx_to_name.items()}
        target_idx = name_to_idx[target_name]
        
        # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë²¡í„°ë¥¼ Faissì—ì„œ ê°€ì ¸ì˜¤ê¸°
        target_vector = index.reconstruct(target_idx).reshape(1, -1)
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (D: ê±°ë¦¬, I: ì¸ë±ìŠ¤)
        distances, indices = index.search(target_vector, TOP_K)
        
        print(f"\nTop {TOP_K} similar items to '{target_name}':")
        print("-" * 50)
        for i, idx in enumerate(indices[0]):
            similar_name = idx_to_name[idx]
            similarity_score = distances[0][i]
            # L2 ê±°ë¦¬ëŠ” ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨
            print(f"{i+1:2d}. {similar_name:<40} (Distance: {similarity_score:.4f})")
            
    except KeyError:
        print(f"\n[âš ï¸ WARNING] Item '{target_name}' not found in the mapping file.")
    except Exception as e:
        print(f"\n[ğŸ”´ ERROR] An error occurred during search: {e}")

if __name__ == "__main__":
    # ì„¤ì •ëœ ëª¨ë“  íƒ€ê²Ÿì— ëŒ€í•´ ê²€ì¦ ë£¨í”„ ì‹¤í–‰
    for node_type, target_name in VERIFICATION_TARGETS.items():
        verify_single_embedding(node_type, target_name)
